{"backend_state":"running","connection_file":"/projects/789aa3e5-de8c-43a9-9498-6199f18e94f7/.local/share/jupyter/runtime/kernel-f9014ea5-cc96-44d6-8dc9-c780bf3b2884.json","kernel":"ds_env","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1657297736701,"exec_count":1,"id":"9e078b","input":"import pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix\nimport sklearn\nfrom numpy import loadtxt\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import recall_score\nfrom sklearn import svm, datasets\nfrom sklearn.model_selection import GridSearchCV","kernel":"ds_env","pos":0,"start":1657297729912,"state":"done","type":"cell"}
{"cell_type":"code","end":1657297736733,"exec_count":2,"id":"54dab3","input":"df = pd.read_csv('heart.csv')","kernel":"ds_env","pos":1,"start":1657297736716,"state":"done","type":"cell"}
{"cell_type":"code","end":1657297739310,"exec_count":3,"id":"01e672","input":"plt.figure(figsize=(15,5))\nsns.boxplot(data=df,orient='h')","kernel":"ds_env","output":{"0":{"data":{"text/plain":"<AxesSubplot:>"},"exec_count":3},"1":{"data":{"image/png":"8cd9da890928fbe53f1352b20367944efe4be76d","text/plain":"<Figure size 1080x360 with 1 Axes>"},"metadata":{"needs_background":"light"}}},"pos":2,"start":1657297738584,"state":"done","type":"cell"}
{"cell_type":"code","end":1657297741012,"exec_count":4,"id":"b6fd8f","input":"q1 = df.chol.quantile(0.25)\nq3 = df.chol.quantile(0.75)\nIQR = q3 - q1\nlower_limit = q1 - 1.5 * IQR\nupper_limit = q3 + 1.5 * IQR\nprint(\"Lower limit for outliers in the column chol is \" + str(lower_limit))\nprint(\"Upper limit for outliers in the column chol is \" + str(upper_limit))","kernel":"ds_env","output":{"0":{"name":"stdout","text":"Lower limit for outliers in the column chol is 115.0\nUpper limit for outliers in the column chol is 371.0\n"}},"pos":3,"start":1657297740996,"state":"done","type":"cell"}
{"cell_type":"code","end":1657297747037,"exec_count":5,"id":"f6f492","input":"df=df[df[\"chol\"] < upper_limit]\nsns.boxplot(df[\"chol\"])","kernel":"ds_env","output":{"0":{"name":"stderr","text":"/projects/789aa3e5-de8c-43a9-9498-6199f18e94f7/miniconda3/envs/ds_env/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  warnings.warn(\n"},"1":{"data":{"text/plain":"<AxesSubplot:xlabel='chol'>"},"exec_count":5},"2":{"data":{"image/png":"bd145278975f3aae3b5d79f345c32046492e332e","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"}}},"pos":4,"start":1657297746822,"state":"done","type":"cell"}
{"cell_type":"code","end":1657297750026,"exec_count":6,"id":"84d31b","input":"# split data\ny = df[\"target\"]\nx = df.drop(\"target\", axis = 1)\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state = 42)","kernel":"ds_env","pos":5,"start":1657297750020,"state":"done","type":"cell"}
{"cell_type":"code","end":1657297751782,"exec_count":7,"id":"50105e","input":"scaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)","kernel":"ds_env","pos":6,"start":1657297751771,"state":"done","type":"cell"}
{"cell_type":"code","end":1657297773843,"exec_count":11,"id":"389df2","input":"parameters = {'booster':['gblinear', 'gbtree'], 'max_depth':([4, 6, 7, 8, 40]), 'sampling_method':['uniform', 'gradient_based']}","kernel":"ds_env","pos":19,"start":1657297773827,"state":"done","type":"cell"}
{"cell_type":"code","end":1657298001937,"exec_count":14,"id":"1984ba","input":"XGB_model_updated = XGBClassifier(booster='gbtree', max_depth=6, sampling_method='uniform')","kernel":"ds_env","pos":26,"start":1657298001928,"state":"done","type":"cell"}
{"cell_type":"code","end":1657298005601,"exec_count":15,"id":"7abc93","input":"XGB_model_updated.fit(x_train, y_train)","kernel":"ds_env","output":{"0":{"data":{"text/html":"<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n              importance_type=None, interaction_constraints=&#x27;&#x27;,\n              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n              importance_type=None, interaction_constraints=&#x27;&#x27;,\n              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>","text/plain":"XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n              importance_type=None, interaction_constraints='',\n              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n              missing=nan, monotone_constraints='()', n_estimators=100,\n              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n              reg_alpha=0, reg_lambda=1, ...)"},"exec_count":15}},"pos":27,"start":1657298004842,"state":"done","type":"cell"}
{"cell_type":"code","end":1657298190416,"exec_count":20,"id":"6b117a","input":"clf = GridSearchCV(XGB_model, parameters, scoring = 'recall')","kernel":"ds_env","pos":20,"scrolled":true,"start":1657298190404,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":0,"id":"239928","input":"#booster, max depth, sampling method","pos":18,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"817a8f","input":"#finding best parameters\ny = df[\"target\"] # only target column\nx = df.drop(\"target\", axis = 1)\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state = 42)","kernel":"ds_env","pos":17,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":11,"id":"d72630","input":"# confusion matrix\nsns.heatmap(confusion_matrix(y_test, XGB_y_hat), annot=True, fmt='g')","output":{"0":{"data":{"text/plain":"<AxesSubplot:>"},"exec_count":11,"output_type":"execute_result"},"1":{"data":{"image/png":"b56c453186c44752be47ce926ee2f8b68d5b3ab1","text/plain":"<Figure size 432x288 with 2 Axes>"},"exec_count":11,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":10,"type":"cell"}
{"cell_type":"code","exec_count":28,"id":"57bccd","input":"np.array(y_test)","output":{"0":{"data":{"text/plain":"array([0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n       1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n       1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n       1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n       0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n       1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n       1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n       1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n       0, 1, 1, 1])"},"exec_count":28,"output_type":"execute_result"}},"pos":9,"type":"cell"}
{"cell_type":"code","exec_count":30,"id":"4c4134","input":"# precision\nXGB_precision = 113/(113+0)\nXGB_precision","output":{"0":{"data":{"text/plain":"1.0"},"exec_count":30,"output_type":"execute_result"}},"pos":11,"type":"cell"}
{"cell_type":"code","exec_count":31,"id":"9913a5","input":"# recall\nXGB_recall = 113/(113+3)\nXGB_recall","output":{"0":{"data":{"text/plain":"0.9741379310344828"},"exec_count":31,"output_type":"execute_result"}},"pos":12,"type":"cell"}
{"cell_type":"code","exec_count":32,"id":"59ef9c","input":"# F1 score\nXGB_F1 = (2*XGB_precision*XGB_recall)/(XGB_precision+XGB_recall)\nXGB_F1","output":{"0":{"data":{"text/plain":"0.9868995633187774"},"exec_count":32,"output_type":"execute_result"}},"pos":13,"type":"cell"}
{"cell_type":"code","exec_count":33,"id":"761b9e","input":"# accuracy\nXGB_accuracy = (113+86)/(113+0+86+3)\nXGB_accuracy","output":{"0":{"data":{"text/plain":"0.9851485148514851"},"exec_count":33,"output_type":"execute_result"}},"pos":14,"type":"cell"}
{"cell_type":"code","exec_count":34,"id":"9627b0","input":"# MSE\nXGB_total_squared_error = (np.sum((y_test - XGB_y_hat)**2))\nXGB_mean_squared_error = XGB_total_squared_error/len(y_test)\nprint(XGB_mean_squared_error)","output":{"0":{"name":"stdout","output_type":"stream","text":"0.01485148514851485\n"}},"pos":15,"type":"cell"}
{"cell_type":"code","exec_count":36,"id":"62da21","input":"recall_score(y_test, XGB_y_hat)","output":{"0":{"data":{"text/plain":"0.9741379310344828"},"exec_count":36,"output_type":"execute_result"}},"pos":16,"type":"cell"}
{"cell_type":"code","exec_count":51,"id":"392b68","input":"clf.best_estimator_","output":{"0":{"data":{"text/html":"<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n              importance_type=None, interaction_constraints=&#x27;&#x27;,\n              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n              max_delta_step=0, max_depth=4, max_leaves=0, min_child_weight=1,\n              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n              importance_type=None, interaction_constraints=&#x27;&#x27;,\n              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n              max_delta_step=0, max_depth=4, max_leaves=0, min_child_weight=1,\n              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>","text/plain":"XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n              importance_type=None, interaction_constraints='',\n              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n              max_delta_step=0, max_depth=4, max_leaves=0, min_child_weight=1,\n              missing=nan, monotone_constraints='()', n_estimators=100,\n              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n              reg_alpha=0, reg_lambda=1, ...)"},"exec_count":51,"output_type":"execute_result"}},"pos":21,"type":"cell"}
{"cell_type":"code","exec_count":62,"id":"d01d99","input":"clf.cv_results_","output":{"0":{"data":{"text/plain":"{'mean_fit_time': array([0.24338999, 0.27379222, 0.24483142, 0.29491282, 0.25385933,\n        0.2909308 , 0.28772001, 0.32330265]),\n 'std_fit_time': array([0.00701867, 0.04347836, 0.00527857, 0.08678262, 0.00894915,\n        0.07767183, 0.0043216 , 0.06617514]),\n 'mean_score_time': array([0.00904937, 0.01938634, 0.01094761, 0.01161289, 0.00662408,\n        0.00667167, 0.0071074 , 0.00700684]),\n 'std_score_time': array([1.10441951e-04, 2.04896023e-02, 2.71906515e-03, 4.94395888e-03,\n        5.97563910e-05, 5.64714927e-05, 2.19511021e-04, 1.36440218e-04]),\n 'param_booster': masked_array(data=['gblinear', 'gblinear', 'gblinear', 'gblinear',\n                    'gbtree', 'gbtree', 'gbtree', 'gbtree'],\n              mask=[False, False, False, False, False, False, False, False],\n        fill_value='?',\n             dtype=object),\n 'param_max_depth': masked_array(data=[1, 1, 40, 40, 1, 1, 40, 40],\n              mask=[False, False, False, False, False, False, False, False],\n        fill_value='?',\n             dtype=object),\n 'param_sampling_method': masked_array(data=['uniform', 'gradient_based', 'uniform',\n                    'gradient_based', 'uniform', 'gradient_based',\n                    'uniform', 'gradient_based'],\n              mask=[False, False, False, False, False, False, False, False],\n        fill_value='?',\n             dtype=object),\n 'params': [{'booster': 'gblinear',\n   'max_depth': 1,\n   'sampling_method': 'uniform'},\n  {'booster': 'gblinear', 'max_depth': 1, 'sampling_method': 'gradient_based'},\n  {'booster': 'gblinear', 'max_depth': 40, 'sampling_method': 'uniform'},\n  {'booster': 'gblinear',\n   'max_depth': 40,\n   'sampling_method': 'gradient_based'},\n  {'booster': 'gbtree', 'max_depth': 1, 'sampling_method': 'uniform'},\n  {'booster': 'gbtree', 'max_depth': 1, 'sampling_method': 'gradient_based'},\n  {'booster': 'gbtree', 'max_depth': 40, 'sampling_method': 'uniform'},\n  {'booster': 'gbtree', 'max_depth': 40, 'sampling_method': 'gradient_based'}],\n 'split0_test_score': array([0.675 , 0.675 , 0.675 , 0.675 , 0.8625, 0.8625, 0.975 , 0.975 ]),\n 'split1_test_score': array([0.82716049, 0.82716049, 0.82716049, 0.82716049, 0.91358025,\n        0.91358025, 0.98765432, 0.98765432]),\n 'split2_test_score': array([0.8  , 0.8  , 0.8  , 0.8  , 0.875, 0.875, 0.95 , 0.95 ]),\n 'split3_test_score': array([0.8125, 0.8125, 0.8125, 0.8125, 0.9125, 0.9125, 0.9625, 0.9625]),\n 'split4_test_score': array([0.725 , 0.725 , 0.725 , 0.725 , 0.9   , 0.9   , 0.9625, 0.9625]),\n 'mean_test_score': array([0.7679321 , 0.7679321 , 0.7679321 , 0.7679321 , 0.89271605,\n        0.89271605, 0.96753086, 0.96753086]),\n 'std_test_score': array([0.05831328, 0.05831328, 0.05831328, 0.05831328, 0.02052629,\n        0.02052629, 0.01279603, 0.01279603]),\n 'rank_test_score': array([5, 5, 5, 5, 3, 3, 1, 1], dtype=int32)}"},"exec_count":62,"output_type":"execute_result"}},"pos":24,"type":"cell"}
{"cell_type":"code","exec_count":75,"id":"c45c41","input":"#new instance of xgb with those best parameters that you found, predict the yhat stuff on xtest, once u get predcitions, find recall score","output":{"0":{"data":{"text/plain":"1.0"},"exec_count":75,"output_type":"execute_result"}},"pos":25,"type":"cell"}
{"cell_type":"code","exec_count":8,"id":"9d8e6e","input":"XGB_model = XGBClassifier() # create an instance\nXGB_model.fit(x_train, y_train) # fit the model","kernel":"ds_env","output":{"0":{"data":{"text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n              importance_type=None, interaction_constraints=&#x27;&#x27;,\n              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n              importance_type=None, interaction_constraints=&#x27;&#x27;,\n              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>","text/plain":"XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n              importance_type=None, interaction_constraints='',\n              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n              missing=nan, monotone_constraints='()', n_estimators=100,\n              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n              reg_alpha=0, reg_lambda=1, ...)"},"exec_count":8}},"pos":7,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":80,"id":"d4e17f","input":"XGB_updated_y_hat = XGB_model_updated.predict(x_test)","pos":28,"type":"cell"}
{"cell_type":"code","exec_count":81,"id":"efe65a","input":"recall_score(y_test, XGB_updated_y_hat)","output":{"0":{"data":{"text/plain":"0.9741379310344828"},"exec_count":81,"output_type":"execute_result"}},"pos":29,"type":"cell"}
{"cell_type":"code","exec_count":9,"id":"a2755c","input":"XGB_y_hat = XGB_model.predict(x_test) # make an area of predicted values to compare with actual values\nXGB_y_hat","kernel":"ds_env","output":{"0":{"data":{"text/plain":"array([0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n       1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n       1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n       1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n       0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n       1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n       1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n       1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n       0, 1, 1, 1])"},"exec_count":9}},"pos":8,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":91,"id":"d4142f","input":"clf.best_score_","output":{"0":{"data":{"text/plain":"0.9775"},"exec_count":91,"output_type":"execute_result"}},"pos":22,"type":"cell"}
{"cell_type":"code","exec_count":98,"id":"a47121","input":"clf.best_params_","output":{"0":{"data":{"text/plain":"{'booster': 'gbtree', 'max_depth': 6, 'sampling_method': 'uniform'}"},"exec_count":98,"output_type":"execute_result"}},"pos":23,"type":"cell"}
{"end":1657298226421,"exec_count":21,"id":"d96da2","input":"clf.fit(x_train, y_train)","kernel":"ds_env","output":{"0":{"name":"stdout","text":"[16:36:33] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"1":{"name":"stdout","text":"[16:36:33] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"10":{"name":"stdout","text":"[16:36:36] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"11":{"name":"stdout","text":"[16:36:36] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"12":{"name":"stdout","text":"[16:36:37] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"13":{"name":"stdout","text":"[16:36:37] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"14":{"name":"stdout","text":"[16:36:37] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"15":{"name":"stdout","text":"[16:36:38] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"16":{"name":"stdout","text":"[16:36:38] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"17":{"name":"stdout","text":"[16:36:38] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"18":{"name":"stdout","text":"[16:36:38] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"19":{"name":"stdout","text":"[16:36:39] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"2":{"name":"stdout","text":"[16:36:34] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"20":{"name":"stdout","text":"[16:36:39] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"21":{"name":"stdout","text":"[16:36:39] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"22":{"name":"stdout","text":"[16:36:40] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"23":{"name":"stdout","text":"[16:36:40] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"24":{"name":"stdout","text":"[16:36:40] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"25":{"name":"stdout","text":"[16:36:41] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"26":{"name":"stdout","text":"[16:36:41] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"27":{"name":"stdout","text":"[16:36:41] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"28":{"name":"stdout","text":"[16:36:41] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"29":{"name":"stdout","text":"[16:36:42] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"3":{"name":"stdout","text":"[16:36:34] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"30":{"name":"stdout","text":"[16:36:42] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"31":{"name":"stdout","text":"[16:36:42] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"32":{"name":"stdout","text":"[16:36:43] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"33":{"name":"stdout","text":"[16:36:43] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"34":{"name":"stdout","text":"[16:36:43] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"35":{"name":"stdout","text":"[16:36:44] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"36":{"name":"stdout","text":"[16:36:44] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"37":{"name":"stdout","text":"[16:36:44] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"38":{"name":"stdout","text":"[16:36:45] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"39":{"name":"stdout","text":"[16:36:45] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"4":{"name":"stdout","text":"[16:36:34] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"40":{"name":"stdout","text":"[16:36:45] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"41":{"name":"stdout","text":"[16:36:45] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"42":{"name":"stdout","text":"[16:36:46] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"43":{"name":"stdout","text":"[16:36:46] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"44":{"name":"stdout","text":"[16:36:46] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"45":{"name":"stdout","text":"[16:36:47] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"46":{"name":"stdout","text":"[16:36:47] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"47":{"name":"stdout","text":"[16:36:47] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"48":{"name":"stdout","text":"[16:36:48] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"49":{"name":"stdout","text":"[16:36:48] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"5":{"name":"stdout","text":"[16:36:35] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"50":{"data":{"text/html":"<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;,\n                                     callbacks=None, colsample_bylevel=1,\n                                     colsample_bynode=1, colsample_bytree=1,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False, eval_metric=None,\n                                     gamma=0, gpu_id=-1,\n                                     grow_policy=&#x27;depthwise&#x27;,\n                                     importance_type=None,\n                                     interaction_constraints=&#x27;&#x27;,\n                                     learning_rate=0.300000012, max_bin=256,\n                                     max_cat_to_onehot=4, max_delta_step=0,\n                                     max_depth=6, max_leaves=0,\n                                     min_child_weight=1, missing=nan,\n                                     monotone_constraints=&#x27;()&#x27;,\n                                     n_estimators=100, n_jobs=0,\n                                     num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n                                     random_state=0, reg_alpha=0, reg_lambda=1, ...),\n             param_grid={&#x27;booster&#x27;: [&#x27;gblinear&#x27;, &#x27;gbtree&#x27;],\n                         &#x27;max_depth&#x27;: [4, 6, 7, 8, 40],\n                         &#x27;sampling_method&#x27;: [&#x27;uniform&#x27;, &#x27;gradient_based&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;,\n                                     callbacks=None, colsample_bylevel=1,\n                                     colsample_bynode=1, colsample_bytree=1,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False, eval_metric=None,\n                                     gamma=0, gpu_id=-1,\n                                     grow_policy=&#x27;depthwise&#x27;,\n                                     importance_type=None,\n                                     interaction_constraints=&#x27;&#x27;,\n                                     learning_rate=0.300000012, max_bin=256,\n                                     max_cat_to_onehot=4, max_delta_step=0,\n                                     max_depth=6, max_leaves=0,\n                                     min_child_weight=1, missing=nan,\n                                     monotone_constraints=&#x27;()&#x27;,\n                                     n_estimators=100, n_jobs=0,\n                                     num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n                                     random_state=0, reg_alpha=0, reg_lambda=1, ...),\n             param_grid={&#x27;booster&#x27;: [&#x27;gblinear&#x27;, &#x27;gbtree&#x27;],\n                         &#x27;max_depth&#x27;: [4, 6, 7, 8, 40],\n                         &#x27;sampling_method&#x27;: [&#x27;uniform&#x27;, &#x27;gradient_based&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n              importance_type=None, interaction_constraints=&#x27;&#x27;,\n              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n              importance_type=None, interaction_constraints=&#x27;&#x27;,\n              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div></div></div></div></div></div>","text/plain":"GridSearchCV(estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n                                     callbacks=None, colsample_bylevel=1,\n                                     colsample_bynode=1, colsample_bytree=1,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False, eval_metric=None,\n                                     gamma=0, gpu_id=-1,\n                                     grow_policy='depthwise',\n                                     importance_type=None,\n                                     interaction_constraints='',\n                                     learning_rate=0.300000012, max_bin=256,\n                                     max_cat_to_onehot=4, max_delta_step=0,\n                                     max_depth=6, max_leaves=0,\n                                     min_child_weight=1, missing=nan,\n                                     monotone_constraints='()',\n                                     n_estimators=100, n_jobs=0,\n                                     num_parallel_tree=1, predictor='auto',\n                                     random_state=0, reg_alpha=0, reg_lambda=1, ...),\n             param_grid={'booster': ['gblinear', 'gbtree'],\n                         'max_depth': [4, 6, 7, 8, 40],\n                         'sampling_method': ['uniform', 'gradient_based']})"},"exec_count":21},"6":{"name":"stdout","text":"[16:36:35] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"7":{"name":"stdout","text":"[16:36:35] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"8":{"name":"stdout","text":"[16:36:35] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"},"9":{"name":"stdout","text":"[16:36:36] WARNING: ../src/learner.cc:627: \nParameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n"}},"pos":20.5,"scrolled":true,"start":1657298193011,"state":"done","type":"cell"}
{"id":0,"time":1657297735739,"type":"user"}
{"last_load":1657297718594,"type":"file"}